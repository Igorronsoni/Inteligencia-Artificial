{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho MPL\n",
    "\n",
    "#### Alunos: Alexsandro Guilherme Thomas, Igor Andrey Ronsoni\n",
    "#### Palavras Chave: Abóbora, Banana, Cenoura\n",
    "#### Repositório Github: [https://github.com/igorronsoni/inteligencia-artificial](https://github.com/igorronsoni/inteligencia-artificial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo para o Sensor CEI\n",
    "\n",
    "Este dataset **\"DataCEI.csv\"** possui informações dispostas em colunas sobre as características dos objetos que passam pelo sensor:\n",
    "\n",
    "* **Tamanho**:  Segue a classificação do CEI2020 (Tamanho='0' - Grande 100%).\n",
    "* **Referencia**:  Referência dinâmica do *Threshold.\n",
    "* **NumAmostra**:  Número de amostras adquiridas.\n",
    "* **Area**:  Somatório das Amplitudes das amostras.\n",
    "* **Delta**:  Máxima Amplitude da amostra.\n",
    "* **Output1**:  Peça tipo 1.\n",
    "* **Output2**:  Peça tipo 2.\n",
    "\n",
    "### Definições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs, display_info = False, False # Poupa tempo se estiver desligado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#Função do cáculo da sigmóide\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando os dados\n",
    "\n",
    "Vamos começar lendo o arquivo DataCEI.csv em um dataframe do pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSet=pd.read_csv('arruela_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if display_info :\n",
    "    DataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSet.drop(['Hora','Tamanho','Referencia'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if display_info :\n",
    "    DataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if display_info :\n",
    "    DataSet.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Váriaveis do *Dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if display_info :\n",
    "    DataSet.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Número de Peças\n",
    "\n",
    "#### Vamos classificar os grupos pelo número de peças: \n",
    "1. Grupo com uma peça\n",
    "2. Grupo com duas peças"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_graphs :\n",
    "    sns.set_style('whitegrid')\n",
    "    sns.countplot(x='Output2',data=DataSet,palette='RdBu_r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gráfico da distribuição das áreas das peças"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_graphs :\n",
    "    sns.distplot(DataSet['Area'].dropna(),kde=False,color='darkred',bins=30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_graphs :\n",
    "    sns.set_style('whitegrid')\n",
    "    sns.countplot(x='Area',hue='Output2',data=DataSet,palette='rainbow')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_graphs :\n",
    "    sns.set_style('whitegrid')\n",
    "    sns.countplot(x='NumAmostra',hue='Output2',data=DataSet,palette='rainbow')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_graphs :\n",
    "    sns.set_style('whitegrid')\n",
    "    sns.countplot(x='Delta',hue='Output1',data=DataSet,palette='rainbow')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As variáveis preditoras e a variável de resposta\n",
    "\n",
    "Para treinar o modelo de regressão, primeiro precisaremos dividir nossos dados em uma matriz **X** que contenha os dados das variáveis preditoras e uma matriz **y** com os dados da variável de destino.\n",
    "\n",
    "### Matrizes X e y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = DataSet[[ 'NumAmostra', 'Area', 'Delta']]\n",
    "#y = DataSet[['Output1','Output2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relação entre as variáveis preditoras\n",
    "\n",
    "####  Algumas questões importantes\n",
    "1. Pelo menos um dos preditores ***x1, x2, ... ,x5***  é útil na previsão da resposta?\n",
    "2. Todos os preditores ajudam a explicar **y**, ou apenas um subconjunto dos preditores?\n",
    "3. Quão bem o modelo se ajusta aos dados?\n",
    "4. Dado um conjunto de valores de previsão, quais valores de resposta devemos prever e quais as métricas indicam um bom modelo de previsão?\n",
    "\n",
    "**Gráficos simples de dispersão**\n",
    "\n",
    "Pelos gráficos abaixo percebemos ... nossa variável de resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_graphs :\n",
    "    sns.pairplot(DataSet)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mapa de Calor**\n",
    "\n",
    "O gráfico abaixo mostra através de uma escala de cores a correlação entre as variáveis do *Dataset*. Se observarmos as cores deste gráfico, a variável preditora **'Area'** possui maior correlação com a variável de resposta **'Output'** e a variável **'NumAmostra'** a menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_graphs :\n",
    "    sns.heatmap(DataSet.corr())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalização dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "DataScaled=scaler.fit_transform(DataSet)\n",
    "DataSetScaled=pd.DataFrame(np.array(DataScaled),columns = ['NumAmostra', 'Area', 'Delta', 'Output1','Output2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if display_info :\n",
    "    DataSetScaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto de dados para o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = DataSetScaled.drop(['Output1', 'Output2'],axis=1)\n",
    "y = DataSet[['Output1','Output2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separando os dados de treinamento e de validação\n",
    "\n",
    "Agora vamos dividir os dados em um conjunto de treinamento e um conjunto de testes. Vamos treinar o modelo no conjunto de treinamento, em seguida, usar o conjunto de teste para validar o modelo.\n",
    "\n",
    "Em nosso exemplo iremos separar de forma randômica 33% dos dados para validação. Estes dados não serão utilizados para determinação dos coeficientes preditores do modelo. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)\n",
    "\n",
    "if display_info :\n",
    "    print(y_test)\n",
    "    print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando o Modelo de MPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tamanho do DataSet de Treinamento\n",
    "n_records, n_features = X_train.shape\n",
    "\n",
    "#Arquitetura da MPL\n",
    "N_input = 3 # Vale a pena cortar alguma entrada?\n",
    "N_hidden = 30 # Vale a pena abaixar ou aumentar?\n",
    "N_output = 2\n",
    "learnrate = 1 # Vale a pena abaixar ou aumentar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialização dos pesos da MPL (Aleatório)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pesos da Camada Oculta (Inicialização Aleatória)\n",
    "weights_input_hidden = np.random.normal(0, scale=0.1, size=(N_input, N_hidden))\n",
    "if display_info :\n",
    "    print('Pesos da Camada Oculta:')\n",
    "    print(weights_input_hidden)\n",
    "\n",
    "#Pesos da Camada de Saída (Inicialização Aleatória)\n",
    "weights_hidden_output = np.random.normal(0, scale=0.1, size=(N_hidden, N_output))\n",
    "if display_info :\n",
    "    print('Pesos da Camada de Saída:')\n",
    "    print(weights_hidden_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executando 20000 épocas com 20 passos de coleção de dados\n",
      "( 1/20) Erro quadrático no treinamento:  0.2950602411664641\n",
      "( 2/20) Erro quadrático no treinamento:  0.05509546788559491\n",
      "( 3/20) Erro quadrático no treinamento:  0.009723861524576029\n",
      "( 4/20) Erro quadrático no treinamento:  0.0035941855880562397\n",
      "( 5/20) Erro quadrático no treinamento:  0.0017894790917270232\n",
      "( 6/20) Erro quadrático no treinamento:  0.0010476981001755667\n",
      "( 7/20) Erro quadrático no treinamento:  0.0006769662179263451\n",
      "( 8/20) Erro quadrático no treinamento:  0.00045483314273884535\n",
      "( 9/20) Erro quadrático no treinamento:  0.00030994059892201916\n",
      "(10/20) Erro quadrático no treinamento:  0.00021157226916617826\n",
      "(11/20) Erro quadrático no treinamento:  0.00014174515090218146\n"
     ]
    }
   ],
   "source": [
    "epochs = 20000\n",
    "n_prints = 20\n",
    "last_loss=None\n",
    "EvolucaoError=[]\n",
    "IndiceError=[]\n",
    "\n",
    "print(f\"Executando {epochs} épocas com {n_prints} passos de coleção de dados\")\n",
    "\n",
    "for e in range(epochs):\n",
    "    delta_w_i_h = np.zeros(weights_input_hidden.shape)\n",
    "    delta_w_h_o = np.zeros(weights_hidden_output.shape)\n",
    "    for xi, yi in zip(X_train.values, y_train.values):\n",
    "        \n",
    "# Forward Pass\n",
    "        #Camada oculta\n",
    "        #Calcule a combinação linear de entradas e pesos sinápticos\n",
    "        hidden_layer_input = np.dot(xi, weights_input_hidden)\n",
    "        #Aplicado a função de ativação\n",
    "        hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "    \n",
    "        #Camada de Saída\n",
    "        #Calcule a combinação linear de entradas e pesos sinápticos\n",
    "        output_layer_in = np.dot(hidden_layer_output, weights_hidden_output)\n",
    "\n",
    "        #Aplicado a função de ativação \n",
    "        output = sigmoid(output_layer_in)\n",
    "        #print('As saídas da rede são',output)\n",
    "#-------------------------------------------    \n",
    "    \n",
    "# Backward Pass\n",
    "        ## TODO: Cálculo do Erro\n",
    "        error = yi - output\n",
    "    \n",
    "        # TODO: Calcule o termo de erro de saída (Gradiente da Camada de Saída)\n",
    "        output_error_term = error * output * (1 - output)\n",
    "\n",
    "        # TODO: Calcule a contribuição da camada oculta para o erro\n",
    "        hidden_error = np.dot(weights_hidden_output,output_error_term)\n",
    "    \n",
    "        # TODO: Calcule o termo de erro da camada oculta (Gradiente da Camada Oculta)\n",
    "        hidden_error_term = hidden_error * hidden_layer_output * (1 - hidden_layer_output)\n",
    "    \n",
    "        # TODO: Calcule a variação do peso da camada de saída\n",
    "        delta_w_h_o += output_error_term*hidden_layer_output[:, None]\n",
    "\n",
    "        # TODO: Calcule a variação do peso da camada oculta\n",
    "        delta_w_i_h += hidden_error_term * xi[:, None]\n",
    "        \n",
    "    #Atualização dos pesos na época em questão\n",
    "    weights_input_hidden += learnrate * delta_w_i_h / n_records\n",
    "    weights_hidden_output += learnrate * delta_w_h_o / n_records\n",
    "    \n",
    "    \n",
    "    # Imprimir o erro quadrático médio no conjunto de treinamento\n",
    "    \n",
    "    if  e % (epochs / n_prints) == 0:\n",
    "        hidden_output = sigmoid(np.dot(xi, weights_input_hidden))\n",
    "        out = sigmoid(np.dot(hidden_output,\n",
    "                             weights_hidden_output))\n",
    "        loss = np.mean((out - yi) ** 2)\n",
    "\n",
    "        print(\"({:2.0f}/{})\".format(e//(epochs / n_prints)+1, n_prints), end=' ')\n",
    "        if last_loss and last_loss < loss:\n",
    "            print(\"Erro quadrático no treinamento: \", loss, \" Atenção: O erro está aumentando\")\n",
    "        else:\n",
    "            print(\"Erro quadrático no treinamento: \", loss)\n",
    "        last_loss = loss\n",
    "         \n",
    "        EvolucaoError.append(loss)\n",
    "        IndiceError.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gráfico da Evolução do Erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(IndiceError, EvolucaoError, 'r') # 'r' is the color red\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Erro Quadrático')\n",
    "plt.title('Evolução do Erro no treinamento da MPL')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcule a precisão dos dados de teste\n",
    "n_records, n_features = X_test.shape\n",
    "predictions=0\n",
    "\n",
    "for xi, yi in zip(X_test.values, y_test.values):\n",
    "\n",
    "# Forward Pass\n",
    "        #Camada oculta\n",
    "        #Calcule a combinação linear de entradas e pesos sinápticos\n",
    "        hidden_layer_input = np.dot(xi, weights_input_hidden)\n",
    "        #Aplicado a função de ativação\n",
    "        hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "    \n",
    "        #Camada de Saída\n",
    "        #Calcule a combinação linear de entradas e pesos sinápticos\n",
    "        output_layer_in = np.dot(hidden_layer_output, weights_hidden_output)\n",
    "\n",
    "        #Aplicado a função de ativação \n",
    "        output = sigmoid(output_layer_in)\n",
    "\n",
    "#-------------------------------------------    \n",
    "    \n",
    "#Cálculo do Erro da Predição\n",
    "        ## TODO: Cálculo do Erro        \n",
    "        if (output[0]>output[1]):\n",
    "            if (yi[0]>yi[1]):\n",
    "                predictions+=1\n",
    "                \n",
    "        if (output[1]>=output[0]):\n",
    "            if (yi[1]>yi[0]):\n",
    "                predictions+=1\n",
    "\n",
    "print(\"Para os pesos:\")\n",
    "\n",
    "print('Camada Oculta:')\n",
    "print(weights_input_hidden)\n",
    "\n",
    "print('Camada de Saída:')\n",
    "print(weights_hidden_output)\n",
    "\n",
    "print(\"A Acurácia da Predição é de: {:.3f}\".format(predictions/n_records))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apreciação dos resultados\n",
    "\n",
    "Formato descritivo, 150 a 500 palavras.\n",
    "\n",
    "Pontos chave para discutir:\n",
    "\n",
    "- Variáveis que tem maior correlação com cada uma das saídas (Quais entradas acabam influênciando mais na saída? Uma análise dos pesos finais revela algo?)\n",
    "- Pesos que levaram ao melhor cenário (quais?)\n",
    "- Acurácia média do treinamento (Pode mudar dependendo da execução, devido à inicialização randômica dos pesos.)\n",
    "- Por que escolhemos o número x de camadas intermediárias? (Melhorou quando subimos? Piorou?)\n",
    "\n",
    "#### Nossa apreciação\n",
    " Após longos períodos de testes e mudanças de variáveis, concluímos que os dados que interferem mais na saída de nossa rede neural é o input: pois quanto mais dados temos, mais nossa Rede neural é capaz de aprender, portanto ao diminuir a quantidade de entradas para um número significativamente pequeno, a porcentagem da acurácia da predição diminui também, outro dado que interfere bastante na saída de nossa rede neural é o campo hidden: após os teste, notamos que quando tínhamos um número um tanto quanto alto de neurônios na camada oculta, a taxa de predição diminuía, mas quando tínhamos um número razoavelmente pequeno também diminui, portanto, concluímos que a quantidade não pode ser exagerada mas também não pode ser pequena, então deixamos ela com 30, porque foi com essa quantidade de neurônios na camada oculta que obtivemos a maior acurácia de predição que se estabilizou em 86.1%.\n",
    " \n",
    " Ao mudar as variáveis diversas e diversas vezes, obtivemos o melhor resultado com o valor de entrada em 3, neurônios na camada oculta em 30 e a saída com 2.\n",
    " \n",
    " A acurácia média girou em torno dos 85%, mas estabilizou como valor mais com os últimos dados inseridos em 86.1% que também foi o maior valor obtido de todos os testes.\n",
    " \n",
    " Os valores de entrada foram escolhidos utilizando uma famosa forma desenvolvida chamada 'tentativa e erro'. De acordo com os resultados obtidos com dados escolhidos, decidimos se deveríamos aumentar ou diminuir determinada variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
